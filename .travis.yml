branches:
  only:
  - master
  # version
  - /^v\d.*/

# Note: with `language: cpp`, `cache: ccache` works
# but `cache: pip` and `python:` is ignored
os:
- linux
language: cpp
dist: focal  # Ubuntu 20.04 LTS
cache:  # cache C/C++/pip (shared between builds)
- ccache
- pip
stages:
- docker-core
- name: docker
  if: NOT type = pull_request

# Compilation dependencies
addons:

jobs:
 include:
 # docker
 - os: linux
   stage: docker-core
   name: docker +CORE
   env: DOCKER_BUILD=CORE
   services:
   - docker
   addons: &docker_addons
    apt:
     packages:
   before_install: &docker_before_install
   - |
      # login required early to increase pull rate limits
      if [[ "$TRAVIS_SECURE_ENV_VARS" == true ]]; then
        echo "$DOCKER_PWD" | docker login -u $DOCKER_USR --password-stdin
      fi
   # custom runtime not supported on travis
   - sed -i '/runtime/d' docker/docker-compose.srv-gpu.yml
   install: &docker_install
   - cd docker
   - if [[ -z "$GROUP_ID" ]]; then export GROUP_ID=$(id -g); fi
   - if [[ -z "$USER_ID" ]]; then export USER_ID=$(id -u); fi
   - export DCC="docker-compose -p "travis_${TRAVIS_JOB_NUMBER/./_}" -f $PWD/docker-compose.yml"
   - if [[ "$DOCKER_BUILD" == *"DEVEL"* ]]; then export DCC="$DCC -f $PWD/docker-compose.devel.yml"; fi
   - if [[ "$DOCKER_BUILD" == *"SERVICE"* ]]; then export DCC="$DCC -f $PWD/docker-compose.srv.yml"; fi
   - if [[ "$DOCKER_BUILD" == *"GPU"* ]]; then export DCC="$DCC -f $PWD/docker-compose.srv-gpu.yml"; fi
   # pull previous base image for its layer cache
   - $DCC pull core
   # rebuild base image (using above docker cache)
   - |
      export DOCKER_BUILDKIT=1
      if [[ "$DOCKER_BUILD" == *"CORE"* ]]; then ( set -ev
        $DCC build --pull core
      ); else ( set -ev
        # rebuild sirf image (with travis' ccache)
        rm -rf devel/.ccache
        if [[ -n "$DOCKER_RECREATE_CCACHE" || ! -d ~/.ccache ]]; then
          mkdir devel/.ccache
          sudo rm -rf ~/.ccache
        else
          sudo chown -R $USER:$(id -g) ~/.ccache
          mv ~/.ccache devel/
        fi
        $DCC build sirf
        # extract updated ccache
        # sudo rm -rf devel/.ccache/*
        $DCC run --rm sirf /bin/bash -c 'rm -rf /devel/.ccache/* && cp -a /opt/ccache/* /devel/.ccache/'
        # replace travis' ccache with the built images's
        mv devel/.ccache ~
      ); fi
   script: &docker_script
   - |
      # run tests within the container
      # Disabled tests as we no longer have ctest files in the container
      true
      # TODO: also add CORE tests!
      # TODO: GPU tests are failing even with nvidia run-time https://github.com/SyneRBI/SIRF-SuperBuild/issues/553
      # if [[ "$DOCKER_BUILD" != *"CORE"* && "$DOCKER_BUILD" != *"GPU"* ]]; then
        # Need to run as jovyan to be able to write to build directory (needed by ctest)
        # $DCC run --rm -u jovyan --entrypoint /bin/bash sirf --login -c /devel/test.sh 1
      # fi
   after_success: &docker_after_success
   - |
      # push images
      if [[ "$TRAVIS_SECURE_ENV_VARS" == true ]]; then ( set -ev
       dpush() {
         # create and push alias $1 -> $2
         if [[ "$1" != "$2" ]]; then
           docker tag synerbi/sirf:$1 synerbi/sirf:$2
         fi
         docker push synerbi/sirf:$2
       }
       if [[ -n "$TRAVIS_TAG" ]]; then ( set -ev
        # tag & push
        case "$DOCKER_BUILD" in
        CORE*)
          ;;
        LATEST)
          dpush latest latest
          dpush latest "$TRAVIS_TAG"
          dpush latest release
          ;;
        DEVEL)
          ;;
        DEVEL_SERVICE)
          ;;
        SERVICE)
          dpush service service
          dpush service "$TRAVIS_TAG"-service
          dpush service release-service
          ;;
        SERVICE_GPU)
          dpush service-gpu service-gpu
          dpush service-gpu "$TRAVIS_TAG"-service-gpu
          dpush service-gpu release-service-gpu
          ;;
        *)
          exit 1
        esac
       ); elif [[ "$TRAVIS_BRANCH" == master ]]; then ( set -ev
        # tag & push
        case "$DOCKER_BUILD" in
        CORE)
          dpush core core
          ;;
        CORE_GPU)
          dpush core-gpu core-gpu
          ;;
        LATEST)
          dpush latest latest
          ;;
        DEVEL)
          dpush devel devel
          ;;
        DEVEL_SERVICE)
          dpush service devel-service
          ;;
        SERVICE)
          dpush service service
          ;;
        SERVICE_GPU)
          dpush service-gpu service-gpu
          ;;
        *)
          exit 1
        esac
       ); fi
      ); fi
 - os: linux
   name: docker +CORE +GPU
   env: DOCKER_BUILD=CORE_GPU
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
 - os: linux
   stage: docker
   name: docker +LATEST
   env: DOCKER_BUILD=LATEST
   services:
   - docker
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
 - os: linux
   name: docker +SERVICE
   env: DOCKER_BUILD=SERVICE
   services:
   - docker
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
 - os: linux
   name: docker +DEVEL
   env: DOCKER_BUILD=DEVEL
   if: branch = master
   services:
   - docker
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
 - os: linux
   name: docker +DEVEL +SERVICE
   env: DOCKER_BUILD=DEVEL_SERVICE
   services:
   - docker
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
 - os: linux
   name: docker +SERVICE +GPU
   env: DOCKER_BUILD=SERVICE_GPU
   services:
   - docker
   addons: *docker_addons
   before_install: *docker_before_install
   install: *docker_install
   script: *docker_script
   after_success: *docker_after_success
